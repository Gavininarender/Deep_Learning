{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset link\n",
    "**link :** https://huggingface.co/datasets/cfilt/iitb-english-hindi\n",
    "\n",
    "# pretrained model link\n",
    "**link :** https://huggingface.co/Helsinki-NLP/opus-mt-en-hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:36:34.984344Z",
     "iopub.status.busy": "2024-01-21T17:36:34.984005Z",
     "iopub.status.idle": "2024-01-21T17:36:36.008114Z",
     "shell.execute_reply": "2024-01-21T17:36:36.007099Z",
     "shell.execute_reply.started": "2024-01-21T17:36:34.984316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 21 17:36:35 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# checking whether GPU is running or not\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:36:37.341348Z",
     "iopub.status.busy": "2024-01-21T17:36:37.340961Z",
     "iopub.status.idle": "2024-01-21T17:36:56.132837Z",
     "shell.execute_reply": "2024-01-21T17:36:56.131627Z",
     "shell.execute_reply.started": "2024-01-21T17:36:37.341321Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:36:56.136443Z",
     "iopub.status.busy": "2024-01-21T17:36:56.136127Z",
     "iopub.status.idle": "2024-01-21T17:37:12.403099Z",
     "shell.execute_reply": "2024-01-21T17:37:12.402188Z",
     "shell.execute_reply.started": "2024-01-21T17:36:56.136416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "from transformers import AdamWeightDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:12.405124Z",
     "iopub.status.busy": "2024-01-21T17:37:12.404529Z",
     "iopub.status.idle": "2024-01-21T17:37:12.409307Z",
     "shell.execute_reply": "2024-01-21T17:37:12.408363Z",
     "shell.execute_reply.started": "2024-01-21T17:37:12.405096Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:12.412569Z",
     "iopub.status.busy": "2024-01-21T17:37:12.412220Z",
     "iopub.status.idle": "2024-01-21T17:37:12.430521Z",
     "shell.execute_reply": "2024-01-21T17:37:12.429618Z",
     "shell.execute_reply.started": "2024-01-21T17:37:12.412544Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:12.432494Z",
     "iopub.status.busy": "2024-01-21T17:37:12.431757Z",
     "iopub.status.idle": "2024-01-21T17:37:21.530627Z",
     "shell.execute_reply": "2024-01-21T17:37:21.529776Z",
     "shell.execute_reply.started": "2024-01-21T17:37:12.432460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a063abe46354989a9f6ccaaffc7b0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default (download: 181.38 MiB, generated: 427.93 MiB, post-processed: Unknown size, total: 609.31 MiB) to /root/.cache/huggingface/datasets/parquet/cfilt--iitb-english-hindi-2cfae92395f2614b/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4f67517d434364b29c76a48723b10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735ed14f9f65481eb0fd9f3cf78d346b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/85.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6af2d7906d2476d92e48404666cccac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/190M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67954be271e04ccf936405fbaed78f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee66c1ad9c442a2a90fbb8f10de5fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/cfilt--iitb-english-hindi-2cfae92395f2614b/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51943794408433eaff4a7434817ed4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"cfilt/iitb-english-hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:21.532093Z",
     "iopub.status.busy": "2024-01-21T17:37:21.531818Z",
     "iopub.status.idle": "2024-01-21T17:37:21.538578Z",
     "shell.execute_reply": "2024-01-21T17:37:21.537627Z",
     "shell.execute_reply.started": "2024-01-21T17:37:21.532069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 520\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1659083\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2507\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:21.540016Z",
     "iopub.status.busy": "2024-01-21T17:37:21.539674Z",
     "iopub.status.idle": "2024-01-21T17:37:21.652607Z",
     "shell.execute_reply": "2024-01-21T17:37:21.651762Z",
     "shell.execute_reply.started": "2024-01-21T17:37:21.539987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'A list of plugins that are disabled by default',\n",
       "  'hi': 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:21.654026Z",
     "iopub.status.busy": "2024-01-21T17:37:21.653763Z",
     "iopub.status.idle": "2024-01-21T17:37:21.669279Z",
     "shell.execute_reply": "2024-01-21T17:37:21.668457Z",
     "shell.execute_reply.started": "2024-01-21T17:37:21.654003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this way he wants to turn Guajrat into an impenetrable fortress. \n",
      " ऐसे में वह गुजरात के किले को पूरी तरह से अभेद बना देना चाहते हैं।\n"
     ]
    }
   ],
   "source": [
    "source_lang = \"en\"\n",
    "target_lang = \"hi\"\n",
    "\n",
    "for i in raw_dataset['validation']['translation']:\n",
    "    inp = i[source_lang]\n",
    "    out = i[target_lang]\n",
    "    \n",
    "print(inp,\"\\n\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:21.670397Z",
     "iopub.status.busy": "2024-01-21T17:37:21.670170Z",
     "iopub.status.idle": "2024-01-21T17:37:23.740604Z",
     "shell.execute_reply": "2024-01-21T17:37:23.739675Z",
     "shell.execute_reply.started": "2024-01-21T17:37:21.670377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e881699dcdc54f91acd845490ba0f8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90455b834b6e4d0e8f0e591faac5a651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d4236785844252a746a164d74953b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1744745d927c4b8bb1798c06e9552387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865810faf71249d1853eab4d7cfd4e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# downloading tokenizers of pretrained model by automatically from hugging face\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for input variable tokenizer checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:23.743371Z",
     "iopub.status.busy": "2024-01-21T17:37:23.743065Z",
     "iopub.status.idle": "2024-01-21T17:37:23.749779Z",
     "shell.execute_reply": "2024-01-21T17:37:23.748765Z",
     "shell.execute_reply.started": "2024-01-21T17:37:23.743345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [39915, 287, 54, 27, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hello how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:23.752019Z",
     "iopub.status.busy": "2024-01-21T17:37:23.751498Z",
     "iopub.status.idle": "2024-01-21T17:37:24.502317Z",
     "shell.execute_reply": "2024-01-21T17:37:24.501295Z",
     "shell.execute_reply.started": "2024-01-21T17:37:23.751982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[39915, 287, 54, 27, 0], [573, 54, 27, 72, 0]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"hello how are you\", \"where are you from\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for target variable tokenizer checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:24.503812Z",
     "iopub.status.busy": "2024-01-21T17:37:24.503473Z",
     "iopub.status.idle": "2024-01-21T17:37:24.514982Z",
     "shell.execute_reply": "2024-01-21T17:37:24.514145Z",
     "shell.execute_reply.started": "2024-01-21T17:37:24.503786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[141, 10076, 69, 38232, 15, 342, 1058, 22433, 246, 12, 2709, 78, 115, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3860: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer([\"उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### converting text data into numerical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:29.961608Z",
     "iopub.status.busy": "2024-01-21T17:37:29.960878Z",
     "iopub.status.idle": "2024-01-21T17:37:29.967885Z",
     "shell.execute_reply": "2024-01-21T17:37:29.966914Z",
     "shell.execute_reply.started": "2024-01-21T17:37:29.961574Z"
    }
   },
   "outputs": [],
   "source": [
    "max_input_len = 128\n",
    "max_target_len = 128\n",
    "\n",
    "source_lang = \"en\"\n",
    "target_lang = \"hi\"\n",
    "\n",
    "def preprocess_func(examples):\n",
    "    inputs = [ex[source_lang] for ex in examples[\"translation\"]] \n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_len, truncation=True)\n",
    "    \n",
    "    # setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_len, truncation=True)\n",
    "        \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:33.311842Z",
     "iopub.status.busy": "2024-01-21T17:37:33.311109Z",
     "iopub.status.idle": "2024-01-21T17:37:33.318968Z",
     "shell.execute_reply": "2024-01-21T17:37:33.317946Z",
     "shell.execute_reply.started": "2024-01-21T17:37:33.311809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[3872, 85, 2501, 132, 15441, 36398, 0], [32643, 28541, 36253, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [[63, 2025, 18, 16155, 346, 20311, 24, 2279, 679, 0], [26618, 16155, 346, 33383, 0]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it returns both tokenizer for engilsh and hindi \n",
    "preprocess_func(raw_dataset['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:37:34.769015Z",
     "iopub.status.busy": "2024-01-21T17:37:34.768406Z",
     "iopub.status.idle": "2024-01-21T17:45:27.128873Z",
     "shell.execute_reply": "2024-01-21T17:45:27.128030Z",
     "shell.execute_reply.started": "2024-01-21T17:37:34.768983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a8be075b6d4a68be69f3d974620afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1166a070b542f68d6def923fccf746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1660 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e18917fa2a94b74a99e25c2b0e21e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = raw_dataset.map(preprocess_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downloading our pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:45:27.130671Z",
     "iopub.status.busy": "2024-01-21T17:45:27.130369Z",
     "iopub.status.idle": "2024-01-21T17:45:40.967317Z",
     "shell.execute_reply": "2024-01-21T17:45:40.966456Z",
     "shell.execute_reply.started": "2024-01-21T17:45:27.130646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec3ef1f874944c5abcb5cc63faba770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dd45d05d9148019d1486a37d9ab340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:45:40.968669Z",
     "iopub.status.busy": "2024-01-21T17:45:40.968395Z",
     "iopub.status.idle": "2024-01-21T17:45:40.973674Z",
     "shell.execute_reply": "2024-01-21T17:45:40.972768Z",
     "shell.execute_reply.started": "2024-01-21T17:45:40.968645Z"
    }
   },
   "outputs": [],
   "source": [
    "'''datacollator means, whenever we define the datacollator, it will take your data as a \n",
    "batches and it will pass it to your model batchwise.'''\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:45:40.976139Z",
     "iopub.status.busy": "2024-01-21T17:45:40.975852Z",
     "iopub.status.idle": "2024-01-21T17:45:40.987339Z",
     "shell.execute_reply": "2024-01-21T17:45:40.986399Z",
     "shell.execute_reply.started": "2024-01-21T17:45:40.976114Z"
    }
   },
   "outputs": [],
   "source": [
    "generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors='tf', \n",
    "                                                  pad_to_multiple_of=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:45:40.988504Z",
     "iopub.status.busy": "2024-01-21T17:45:40.988274Z",
     "iopub.status.idle": "2024-01-21T17:45:40.998164Z",
     "shell.execute_reply": "2024-01-21T17:45:40.997234Z",
     "shell.execute_reply.started": "2024-01-21T17:45:40.988484Z"
    }
   },
   "outputs": [],
   "source": [
    "np.object = object    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:45:40.999611Z",
     "iopub.status.busy": "2024-01-21T17:45:40.999322Z",
     "iopub.status.idle": "2024-01-21T17:45:41.462409Z",
     "shell.execute_reply": "2024-01-21T17:45:41.461590Z",
     "shell.execute_reply.started": "2024-01-21T17:45:40.999578Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "\n",
    "\n",
    "train_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_data[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "validation_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_data[\"validation\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "\n",
    "generation_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_data[\"validation\"],\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:45:41.464113Z",
     "iopub.status.busy": "2024-01-21T17:45:41.463754Z",
     "iopub.status.idle": "2024-01-21T17:45:41.481195Z",
     "shell.execute_reply": "2024-01-21T17:45:41.480321Z",
     "shell.execute_reply.started": "2024-01-21T17:45:41.464081Z"
    }
   },
   "outputs": [],
   "source": [
    "# we are using AdamWeightDecay\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T17:50:14.902430Z",
     "iopub.status.busy": "2024-01-21T17:50:14.901697Z",
     "iopub.status.idle": "2024-01-21T18:24:49.552100Z",
     "shell.execute_reply": "2024-01-21T18:24:49.551154Z",
     "shell.execute_reply.started": "2024-01-21T17:50:14.902399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 39s 313ms/step - loss: 3.2754 - val_loss: 3.8607\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 40s 321ms/step - loss: 3.0151 - val_loss: 3.8217\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 40s 321ms/step - loss: 2.7862 - val_loss: 3.8155\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 41s 325ms/step - loss: 2.5891 - val_loss: 3.8082\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 41s 327ms/step - loss: 2.4187 - val_loss: 3.8211\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 41s 328ms/step - loss: 2.2661 - val_loss: 3.8204\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 42s 335ms/step - loss: 2.1131 - val_loss: 3.8350\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 42s 333ms/step - loss: 1.9828 - val_loss: 3.8477\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 41s 332ms/step - loss: 1.8594 - val_loss: 3.8572\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 41s 330ms/step - loss: 1.7354 - val_loss: 3.8842\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 42s 334ms/step - loss: 1.6199 - val_loss: 3.9043\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 42s 338ms/step - loss: 1.5220 - val_loss: 3.9282\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 42s 334ms/step - loss: 1.4235 - val_loss: 3.9488\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 42s 336ms/step - loss: 1.3298 - val_loss: 3.9678\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 42s 334ms/step - loss: 1.2424 - val_loss: 3.9905\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 41s 332ms/step - loss: 1.1564 - val_loss: 4.0324\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 42s 337ms/step - loss: 1.0784 - val_loss: 4.0583\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 42s 333ms/step - loss: 1.0078 - val_loss: 4.0803\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 42s 334ms/step - loss: 0.9410 - val_loss: 4.0981\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 41s 332ms/step - loss: 0.8764 - val_loss: 4.1414\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 41s 329ms/step - loss: 0.8161 - val_loss: 4.1618\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 42s 336ms/step - loss: 0.7620 - val_loss: 4.1868\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 41s 330ms/step - loss: 0.7037 - val_loss: 4.2070\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 42s 335ms/step - loss: 0.6608 - val_loss: 4.2497\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 42s 336ms/step - loss: 0.6133 - val_loss: 4.2640\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 41s 330ms/step - loss: 0.5700 - val_loss: 4.2927\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 42s 332ms/step - loss: 0.5315 - val_loss: 4.3179\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 41s 329ms/step - loss: 0.4925 - val_loss: 4.3458\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 42s 333ms/step - loss: 0.4586 - val_loss: 4.3721\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 42s 335ms/step - loss: 0.4276 - val_loss: 4.3932\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 42s 338ms/step - loss: 0.4037 - val_loss: 4.4077\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 42s 334ms/step - loss: 0.3747 - val_loss: 4.4361\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 42s 336ms/step - loss: 0.3497 - val_loss: 4.4552\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 42s 333ms/step - loss: 0.3234 - val_loss: 4.4885\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 42s 334ms/step - loss: 0.3040 - val_loss: 4.5083\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 42s 333ms/step - loss: 0.2835 - val_loss: 4.5397\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 41s 330ms/step - loss: 0.2640 - val_loss: 4.5440\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 42s 336ms/step - loss: 0.2490 - val_loss: 4.5810\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 42s 333ms/step - loss: 0.2334 - val_loss: 4.6079\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 42s 335ms/step - loss: 0.2187 - val_loss: 4.6118\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 42s 332ms/step - loss: 0.2059 - val_loss: 4.6363\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 41s 332ms/step - loss: 0.1933 - val_loss: 4.6652\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 42s 334ms/step - loss: 0.1808 - val_loss: 4.6652\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 41s 330ms/step - loss: 0.1695 - val_loss: 4.6968\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 42s 332ms/step - loss: 0.1599 - val_loss: 4.7022\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 41s 329ms/step - loss: 0.1521 - val_loss: 4.7191\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 42s 335ms/step - loss: 0.1440 - val_loss: 4.7328\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 41s 329ms/step - loss: 0.1344 - val_loss: 4.7557\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 42s 334ms/step - loss: 0.1290 - val_loss: 4.7753\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 42s 335ms/step - loss: 0.1205 - val_loss: 4.7795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7e26e6b106d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:24:49.554200Z",
     "iopub.status.busy": "2024-01-21T18:24:49.553872Z",
     "iopub.status.idle": "2024-01-21T18:24:50.633539Z",
     "shell.execute_reply": "2024-01-21T18:24:50.632763Z",
     "shell.execute_reply.started": "2024-01-21T18:24:49.554172Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"translation_tf_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:24:50.635009Z",
     "iopub.status.busy": "2024-01-21T18:24:50.634729Z",
     "iopub.status.idle": "2024-01-21T18:24:54.119244Z",
     "shell.execute_reply": "2024-01-21T18:24:54.118441Z",
     "shell.execute_reply.started": "2024-01-21T18:24:50.634986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at /kaggle/working/translation_tf_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/translation_tf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:24:54.121196Z",
     "iopub.status.busy": "2024-01-21T18:24:54.120918Z",
     "iopub.status.idle": "2024-01-21T18:24:57.165013Z",
     "shell.execute_reply": "2024-01-21T18:24:57.164084Z",
     "shell.execute_reply.started": "2024-01-21T18:24:54.121171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[61949   707  6001     2   118   280    28    22     0 61949]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hey! how are you\"\n",
    "\n",
    "tokenized = tokenizer([input_text], return_tensors='np')\n",
    "out = model.generate(**tokenized, max_length=128)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:24:57.166593Z",
     "iopub.status.busy": "2024-01-21T18:24:57.166238Z",
     "iopub.status.idle": "2024-01-21T18:24:57.173674Z",
     "shell.execute_reply": "2024-01-21T18:24:57.172667Z",
     "shell.execute_reply.started": "2024-01-21T18:24:57.166557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "हे भगवान, आप कैसे हैं?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3860: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### please increase no.of.epochs during training time, so our model can translate accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:26:04.044574Z",
     "iopub.status.busy": "2024-01-21T18:26:04.044210Z",
     "iopub.status.idle": "2024-01-21T18:26:06.669186Z",
     "shell.execute_reply": "2024-01-21T18:26:06.668151Z",
     "shell.execute_reply.started": "2024-01-21T18:26:04.044546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[61949  5201   500   179    67   130 10916  3130     5     0]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hi my name is Narender\"\n",
    "\n",
    "tokenized = tokenizer([input_text], return_tensors='np')\n",
    "out = model.generate(**tokenized, max_length=128)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T18:26:06.671284Z",
     "iopub.status.busy": "2024-01-21T18:26:06.670935Z",
     "iopub.status.idle": "2024-01-21T18:26:06.677868Z",
     "shell.execute_reply": "2024-01-21T18:26:06.677066Z",
     "shell.execute_reply.started": "2024-01-21T18:26:06.671250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "हाय मेरा नाम नीशेद है\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

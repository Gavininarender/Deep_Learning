{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a command to install six Python packages using the pip package manager. The packages are:\n",
    "\n",
    "- **transformers[sentencepiece]**: A library that provides state-of-the-art natural language processing models and tools, with an optional dependency on SentencePiece, a library for subword tokenization.\n",
    "- **datasets**: A library that provides easy access to a wide range of datasets and metrics for natural language processing.\n",
    "- **sacrebleu**: A library that provides hassle-free computation of shareable, comparable, and reproducible BLEU, chrF, and TER scores for machine translation evaluation.\n",
    "- **rouge_score**: A library that provides Python implementations of ROUGE-L, ROUGE-N, and ROUGE-W for automatic summarization evaluation.\n",
    "- **py7zr**: A library that provides a pure python module for reading and writing 7z files.\n",
    "\n",
    "The `-q` option means to give less output during the installation process. This option is useful to reduce the clutter on the screen.\n",
    "\n",
    "These packages are often used together for tasks such as machine translation and text summarization, where the goal is to generate natural language text from some input. For example, one can use the transformers library to fine-tune a pretrained model, such as MT5, on a machine translation or text summarization dataset, such as XSUM. Then, one can use the datasets library to load and preprocess the data, the sacrebleu and rouge_score libraries to evaluate the model performance, and the py7zr library to compress or decompress the data or model files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R91DCZYqiK_b"
   },
   "source": [
    "## installing required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbhE80R4ifsn"
   },
   "source": [
    "#### metrixs --> rouge_score, it is used in summerization task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1YuqjB1hfR6"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7XOvkR-hfT7",
    "outputId": "07916b84-e313-48d0-a75d-09bd963cb8c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 21 09:38:34 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   60C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# checking whether GPU is running or not\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsuMRVXenoR7"
   },
   "source": [
    "### pipeline --> we need pipeline because , whenever we will be doing inferencing , we need to call pipeline, so inside the pipeline we will be mentioned our task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjzMKLdWhfXf",
    "outputId": "fa96814b-5714-479c-f570-866bd9a26755"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7xB0RyWhfZa"
   },
   "outputs": [],
   "source": [
    "# it will check whether i have selected GPU or not, if GPU is selected then, it return \"cuda\" other wise \"cpu\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "dWV74gFShfcq",
    "outputId": "997cbafa-545f-4dec-b76e-b10310a22685"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Af67e4jpgJi"
   },
   "source": [
    "### retrieving our pretrained model from hugging face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_1NqiNpsBVi"
   },
   "outputs": [],
   "source": [
    "model_ckpt =  \"google/pegasus-cnn_dailymail\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXi3F1yBsFaz"
   },
   "source": [
    "### initializing our tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XSNfbDFhfeu",
    "outputId": "afc1bdf5-6761-4bf2-a87f-8f01c4a66bb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# downloading tokenizers of pretrained model by automatically from hugging face\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1pzcC7LsJ5E"
   },
   "source": [
    "### downloading our pretrained model from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-kHXF37hfiH",
    "outputId": "e2591cf4-f845-417f-f48b-68a747d75656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# initialization of our pretrained model\n",
    "# AutoModelForSeq2SeqLM --> our task is text summerization (given seq and it return seq only), so we use this model\n",
    "# downloading our pretrained model from hugging face\n",
    "# which device we should use  during traing time \"cpu\" or \"cuda\" --> now it is running on \"GPU\"\n",
    "\n",
    "model_pegasum = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrKB7UaWsSnq"
   },
   "source": [
    "### load our data\n",
    "\n",
    "Link: https://huggingface.co/datasets/samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QwyzGtihfkD"
   },
   "outputs": [],
   "source": [
    "dataset_samsum = load_dataset(\"samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LjldcQsghgLJ",
    "outputId": "2cc34343-a0ae-48a7-ee2d-f1966cc3e922"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmf_hDYVt0JA",
    "outputId": "df5fcaf3-6a28-40e0-8e65-2faa149a0487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'dialogue', 'summary'],\n",
      "    num_rows: 14732\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'dialogue', 'summary'],\n",
      "    num_rows: 819\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'dialogue', 'summary'],\n",
      "    num_rows: 818\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "for split in dataset_samsum:\n",
    "  print(dataset_samsum[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmIDFo6dhgMu",
    "outputId": "2030fb2c-cfe8-4856-e788-bc57207dedca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14732, 819, 818]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_len = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
    "split_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOcNeWcys7u8",
    "outputId": "5a02628d-ce2f-4345-df89-7c65397967d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: ['id', 'dialogue', 'summary']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature: {dataset_samsum['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKCcTkTEs7w1",
    "outputId": "9e894d23-c3ac-41dc-f506-1eb9fa435ae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue\n",
      "Eric: MACHINE!\r\n",
      "Rob: That's so gr8!\r\n",
      "Eric: I know! And shows how Americans see Russian ;)\r\n",
      "Rob: And it's really funny!\r\n",
      "Eric: I know! I especially like the train part!\r\n",
      "Rob: Hahaha! No one talks to the machine like that!\r\n",
      "Eric: Is this his only stand-up?\r\n",
      "Rob: Idk. I'll check.\r\n",
      "Eric: Sure.\r\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\r\n",
      "Eric: Gr8! I'll watch them now!\r\n",
      "Rob: Me too!\r\n",
      "Eric: MACHINE!\r\n",
      "Rob: MACHINE!\r\n",
      "Eric: TTYL?\r\n",
      "Rob: Sure :)\n",
      "\n",
      "Summary\n",
      "Eric and Rob are going to watch a stand-up on youtube.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDialogue\")\n",
    "\n",
    "print(dataset_samsum[\"test\"][1][\"dialogue\"])\n",
    "\n",
    "print(\"\\nSummary\")\n",
    "\n",
    "print(dataset_samsum[\"test\"][1][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgf07Jakwd7r"
   },
   "source": [
    "## we are using pretrained model and checking whether it works good or not. if not, then we do fine tuing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwQNZxRIviIh"
   },
   "source": [
    "### evaluating PEGASUS on SAMSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRCPayEds7zx",
    "outputId": "97a02511-08a0-4758-e615-9a7a6dfe0a68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13862856',\n",
       " 'dialogue': \"Hannah: Hey, do you have Betty's number?\\nAmanda: Lemme check\\nHannah: <file_gif>\\nAmanda: Sorry, can't find it.\\nAmanda: Ask Larry\\nAmanda: He called her last time we were at the park together\\nHannah: I don't know him well\\nHannah: <file_gif>\\nAmanda: Don't be shy, he's very nice\\nHannah: If you say so..\\nHannah: I'd rather you texted him\\nAmanda: Just text him ðŸ™‚\\nHannah: Urgh.. Alright\\nHannah: Bye\\nAmanda: Bye bye\",\n",
       " 'summary': \"Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "sDECMcads71V",
    "outputId": "0c929cd8-26d1-43f4-fd0f-c19b116e7eb2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hannah: Hey, do you have Betty's number?\\nAmanda: Lemme check\\nHannah: <file_gif>\\nAmanda: Sorry, can't find it.\\nAmanda: Ask Larry\\nAmanda: He called her last time we were at the park together\\nHannah: I don't know him well\\nHannah: <file_gif>\\nAmanda: Don't be shy, he's very nice\\nHannah: If you say so..\\nHannah: I'd rather you texted him\\nAmanda: Just text him ðŸ™‚\\nHannah: Urgh.. Alright\\nHannah: Bye\\nAmanda: Bye bye\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue = dataset_samsum['test'][0]['dialogue']\n",
    "dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vY46-TLns74s",
    "outputId": "4121c91e-bccd-4f2e-e325-b8e073b3d181"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('summarization', model = model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "500ecCMIs76q",
    "outputId": "e5555ff1-9fe3-4cd2-d961-2784229f05b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Amanda: Ask Larry Amanda: He called her last time we were at the park together .<n>Hannah: I'd rather you texted him .<n>Amanda: Just text him .\"}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "pipe_out = pipe(dialogue)\n",
    "pipe_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmfqK6rks79w",
    "outputId": "6a7facc0-a236-458d-a79f-5bbcd8133f91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amanda: Ask Larry Amanda: He called her last time we were at the park together.\n",
      "Hannah: I'd rather you texted him.\n",
      "Amanda: Just text him .\n"
     ]
    }
   ],
   "source": [
    "'''prediction is not well because our \"samsum\" dataset is not trained, so now we use fine tuning approach with\n",
    "our own data or custom data.'''\n",
    "\n",
    "print(pipe_out[0][\"summary_text\"].replace(' .<n>', '.\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6D0H2EZgzFQ5"
   },
   "outputs": [],
   "source": [
    "# here we are not loading entire data to my memory, so i will pass my data by batch_wise\n",
    "\n",
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "  \"\"\"split the dataset into smaller batches that we can process simlutaneously yield successive batch_sized\n",
    "  chunks from list_of_elements\"\"\"\n",
    "  for i in range(0, len(list_of_elements), batch_size):\n",
    "    yield list_of_elements[i:i+batch_size]\n",
    "\n",
    "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n",
    "\n",
    "        # Finally, we decode the generated texts,\n",
    "        # replace the  token, and add the decoded texts with the references to the metric.\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "\n",
    "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "\n",
    "\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    #  Finally compute and return the ROUGE scores.\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbI_fBSX2Otn",
    "outputId": "65e891f0-285d-4fdb-88ba-02319578824e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [18:19<00:00, 10.68s/it]\n"
     ]
    }
   ],
   "source": [
    "rouge_metric = load_metric('rouge')\n",
    "\n",
    "'''checking an accuracy with pegasum model'''\n",
    "\n",
    "score = calculate_metric_on_test_ds(dataset_samsum['test'], rouge_metric, model_pegasum, tokenizer, column_text = 'dialogue',\n",
    "                                    column_summary='summary', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "Vhb1TnDLzAEQ",
    "outputId": "30c9788d-4e23-4279-a756-ef15fe1583eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-15d715c0-e0c2-41c6-b689-21676e6d8642\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.015548</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>0.015511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15d715c0-e0c2-41c6-b689-21676e6d8642')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-15d715c0-e0c2-41c6-b689-21676e6d8642 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-15d715c0-e0c2-41c6-b689-21676e6d8642');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.015548  0.000302  0.015509   0.015511"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# types of rouge metrics\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "\n",
    "pd.DataFrame(rouge_dict, index = ['pegasus'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxR-S15oBvoE"
   },
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "1pqj2ZDBBxP-",
    "outputId": "42c1cc02-6d0d-428e-86cd-213c8af1c22b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dialogue_token_len = len([tokenizer.encode(s) for s in dataset_samsum['train']['dialogue']])\n",
    "\n",
    "summary_token_len = len([tokenizer.encode(s) for s in dataset_samsum['train']['summary']])\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].hist(dialogue_token_len, bins = 20, color = 'C0', edgecolor = 'C0' )\n",
    "axes[0].set_title(\"Dialogue Token Length\")\n",
    "axes[0].set_xlabel(\"Length\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "axes[1].hist(summary_token_len, bins = 20, color = 'C0', edgecolor = 'C0' )\n",
    "axes[1].set_title(\"Summary Token Length\")\n",
    "axes[1].set_xlabel(\"Length\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8VWqycSBlum"
   },
   "source": [
    "### converting text to numerical representatinon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qK2vOYy4zAHw",
    "outputId": "e5f3e5fb-4c1a-4fa0-fdd7-c6cadf478eec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13818513',\n",
       " 'dialogue': \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n",
       " 'summary': 'Amanda baked cookies and will bring Jerry some tomorrow.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "1f5c46eb0c034cd4bde59c26ad4b43e1",
      "53b765cbc525429a8b12cca3aaf20bdc",
      "12ef245cf61444cab310f3c7b014547d",
      "0782e6116d6f4ee28befa3d383a378a9",
      "47492c761a4c4255bd27849eee6058c2",
      "dae25b78e65e4e2f82bcaf70a76ee919",
      "61c1fc7ba75d4c8c959249f9887853b7",
      "cbd6e6771833457aa070a5f2750203b3",
      "f3bc618c34f445fcb787d6cf26aa5ddb",
      "bfaf2484acfa4e209cac16057b15ffbe",
      "5762910f07044004be2be0c8e76ae5f0"
     ]
    },
    "id": "eUqz1Yocs8CF",
    "outputId": "460f6b2e-1983-422c-a351-367f550364be"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5c46eb0c034cd4bde59c26ad4b43e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
    "\n",
    "    return {\n",
    "        'input_ids' : input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "\n",
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CxVVg6Zs8EW",
    "outputId": "4b9e6f2a-cbda-42a5-ea6f-a5113190838b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13818513',\n",
       " 'dialogue': \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n",
       " 'summary': 'Amanda baked cookies and will bring Jerry some tomorrow.',\n",
       " 'input_ids': [12195,\n",
       "  151,\n",
       "  125,\n",
       "  7091,\n",
       "  3659,\n",
       "  107,\n",
       "  842,\n",
       "  119,\n",
       "  245,\n",
       "  181,\n",
       "  152,\n",
       "  10508,\n",
       "  151,\n",
       "  7435,\n",
       "  147,\n",
       "  12195,\n",
       "  151,\n",
       "  125,\n",
       "  131,\n",
       "  267,\n",
       "  650,\n",
       "  119,\n",
       "  3469,\n",
       "  29344,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [12195, 7091, 3659, 111, 138, 650, 10508, 181, 3469, 107, 1]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcpQODyaER6t"
   },
   "source": [
    "### training and validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax4uH2vjhgRa"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# datacollator means, whenever we define the datacollator, it will take your data as a batches and it will pass it to your model batchwise.\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZqJu1-KXvZj",
    "outputId": "9c47348b-7941-4ff8-997c-f5e23bffedbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW6awIudhgTU"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "trainer_args = TrainingArguments(\n",
    "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10,\n",
    "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "    gradient_accumulation_steps=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOLlzk8fDd15"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model_pegasum, args=trainer_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt[\"train\"],\n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "wBkktbzBDd3t",
    "outputId": "1bd42b65-5610-404e-8e8f-5dc23f08be38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [920/920 44:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.626500</td>\n",
       "      <td>1.484255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=920, training_loss=1.8238315105438232, metrics={'train_runtime': 2678.0229, 'train_samples_per_second': 5.501, 'train_steps_per_second': 0.344, 'total_flos': 5526698901602304.0, 'train_loss': 1.8238315105438232, 'epoch': 1.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "ycmcWm-uDd6d",
    "outputId": "b513f142-659d-46b8-a077-fae865b902bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [13:04<00:00,  1.91s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a74544dd-a578-4c48-926f-6d424982ceea\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.018603</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.018451</td>\n",
       "      <td>0.018462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a74544dd-a578-4c48-926f-6d424982ceea')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a74544dd-a578-4c48-926f-6d424982ceea button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a74544dd-a578-4c48-926f-6d424982ceea');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.018603  0.000328  0.018451   0.018462"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = calculate_metric_on_test_ds(dataset_samsum['test'], rouge_metric, trainer.model, tokenizer, column_text = 'dialogue',\n",
    "                                    column_summary='summary', batch_size=2)\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "\n",
    "pd.DataFrame(rouge_dict, index = [f'pegasus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqb7iOW4Dd8L"
   },
   "outputs": [],
   "source": [
    "# save our model\n",
    "\n",
    "model_pegasum.save_pretrained('pegasus-samsum-fmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYANQh1lDd_w",
    "outputId": "2f64b241-b203-4b96-e3ec-28ad356cd4d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/spiece.model',\n",
       " 'tokenizer/added_tokens.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save tokenizer\n",
    "tokenizer.save_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3DwljS5GHPk"
   },
   "source": [
    "## Inferencing using our trained model, retrieving our trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nan-AFswGFNO"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVxDCXAYGFPS"
   },
   "outputs": [],
   "source": [
    "dataset_samsum = load_dataset('samsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0p2VE2UGFS1"
   },
   "outputs": [],
   "source": [
    "sample_text = dataset_samsum['test'][0]['dialogue']\n",
    "\n",
    "reference = dataset_samsum['test'][0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "Uxn4gu7GGFVH",
    "outputId": "aeb36f32-ab0b-4205-f42f-5affa5b858c9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hannah: Hey, do you have Betty's number?\\nAmanda: Lemme check\\nHannah: <file_gif>\\nAmanda: Sorry, can't find it.\\nAmanda: Ask Larry\\nAmanda: He called her last time we were at the park together\\nHannah: I don't know him well\\nHannah: <file_gif>\\nAmanda: Don't be shy, he's very nice\\nHannah: If you say so..\\nHannah: I'd rather you texted him\\nAmanda: Just text him ðŸ™‚\\nHannah: Urgh.. Alright\\nHannah: Bye\\nAmanda: Bye bye\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "vy9mtL8HGFXp",
    "outputId": "3fd85bcd-a008-407a-e98d-64f98b2fa85d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtxNkYbDGFcX"
   },
   "outputs": [],
   "source": [
    "gen_kwargs = {\"length_penalty\":0.8, \"num_beams\":8, \"max_length\":128}\n",
    "\n",
    "pipe = pipeline(\"summarization\", model='/content/pegasus-samsum-fmodel', tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1_SFmkvGFfG",
    "outputId": "e80987bf-5640-47a5-9d55-68406f992322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Rference Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "print('Dialogue')\n",
    "print(sample_text)\n",
    "\n",
    "print(\"\\nRference Summary:\")\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czsnsdMdIdXI",
    "outputId": "d7900da9-ed69-4234-b2ea-f06374d63952"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n",
      "Hannah is looking for Betty's number. Amanda can't find it. Larry called Betty last time they were at the park together. Hannah would rather she text him.\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkNYJFOmsds4"
   },
   "outputs": [],
   "source": [
    "sample_text = dataset_samsum['test'][4]['dialogue']\n",
    "\n",
    "reference = dataset_samsum['test'][4]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "eU2mWMCNslwp",
    "outputId": "d6262f84-2f05-4a33-fe9a-baafa3bf7984"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Ollie: Hi , are you in Warsaw\\r\\nJane: yes, just back! Btw are you free for diner the 19th?\\r\\nOllie: nope!\\r\\nJane: and the  18th?\\r\\nOllie: nope, we have this party and you must be there, remember?\\r\\nJane: oh right! i lost my calendar..  thanks for reminding me\\r\\nOllie: we have lunch this week?\\r\\nJane: with pleasure!\\r\\nOllie: friday?\\r\\nJane: ok\\r\\nJane: what do you mean \" we don\\'t have any more whisky!\" lol..\\r\\nOllie: what!!!\\r\\nJane: you just call me and the all thing i heard was that sentence about whisky... what\\'s wrong with you?\\r\\nOllie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\\r\\nJane: dont\\' worry, we\\'ll check on friday.\\r\\nOllie: don\\'t forget to bring some sun with you\\r\\nJane: I can\\'t wait to be in Morocco..\\r\\nOllie: enjoy and see you friday\\r\\nJane: sorry Ollie, i\\'m very busy, i won\\'t have time for lunch  tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\\r\\nOllie: ok for tea!\\r\\nJane: I\\'m on my way..\\r\\nOllie: tea is ready, did you bring the pastries?\\r\\nJane: I already ate them all... see you in a minute\\r\\nOllie: ok'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "TYnOmYD8slzj",
    "outputId": "b7a800db-4dcb-4de5-df1a-2a1a98d33200"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlMzqNp0sxmG",
    "outputId": "dbeab93d-7f92-4cc9-9163-2d53a1d3d318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue\n",
      "Ollie: Hi , are you in Warsaw\r\n",
      "Jane: yes, just back! Btw are you free for diner the 19th?\r\n",
      "Ollie: nope!\r\n",
      "Jane: and the  18th?\r\n",
      "Ollie: nope, we have this party and you must be there, remember?\r\n",
      "Jane: oh right! i lost my calendar..  thanks for reminding me\r\n",
      "Ollie: we have lunch this week?\r\n",
      "Jane: with pleasure!\r\n",
      "Ollie: friday?\r\n",
      "Jane: ok\r\n",
      "Jane: what do you mean \" we don't have any more whisky!\" lol..\r\n",
      "Ollie: what!!!\r\n",
      "Jane: you just call me and the all thing i heard was that sentence about whisky... what's wrong with you?\r\n",
      "Ollie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\r\n",
      "Jane: dont' worry, we'll check on friday.\r\n",
      "Ollie: don't forget to bring some sun with you\r\n",
      "Jane: I can't wait to be in Morocco..\r\n",
      "Ollie: enjoy and see you friday\r\n",
      "Jane: sorry Ollie, i'm very busy, i won't have time for lunch  tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\r\n",
      "Ollie: ok for tea!\r\n",
      "Jane: I'm on my way..\r\n",
      "Ollie: tea is ready, did you bring the pastries?\r\n",
      "Jane: I already ate them all... see you in a minute\r\n",
      "Ollie: ok\n",
      "\n",
      "Rference Summary:\n",
      "Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\n"
     ]
    }
   ],
   "source": [
    "print('Dialogue')\n",
    "print(sample_text)\n",
    "\n",
    "print(\"\\nRference Summary:\")\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfWAFL7YIdZF",
    "outputId": "3c20d4a2-e497-4c66-da1d-5b911300db30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n",
      "Jane is back in Warsaw. She lost her calendar. She's going to meet with Ollie on Friday. She'll bring some sun with her.\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qz5fliXBIdcC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0782e6116d6f4ee28befa3d383a378a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfaf2484acfa4e209cac16057b15ffbe",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5762910f07044004be2be0c8e76ae5f0",
      "value": " 818/818 [00:00&lt;00:00, 1874.89 examples/s]"
     }
    },
    "12ef245cf61444cab310f3c7b014547d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbd6e6771833457aa070a5f2750203b3",
      "max": 818,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3bc618c34f445fcb787d6cf26aa5ddb",
      "value": 818
     }
    },
    "1f5c46eb0c034cd4bde59c26ad4b43e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53b765cbc525429a8b12cca3aaf20bdc",
       "IPY_MODEL_12ef245cf61444cab310f3c7b014547d",
       "IPY_MODEL_0782e6116d6f4ee28befa3d383a378a9"
      ],
      "layout": "IPY_MODEL_47492c761a4c4255bd27849eee6058c2"
     }
    },
    "47492c761a4c4255bd27849eee6058c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53b765cbc525429a8b12cca3aaf20bdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dae25b78e65e4e2f82bcaf70a76ee919",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_61c1fc7ba75d4c8c959249f9887853b7",
      "value": "Map: 100%"
     }
    },
    "5762910f07044004be2be0c8e76ae5f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61c1fc7ba75d4c8c959249f9887853b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bfaf2484acfa4e209cac16057b15ffbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbd6e6771833457aa070a5f2750203b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dae25b78e65e4e2f82bcaf70a76ee919": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3bc618c34f445fcb787d6cf26aa5ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
